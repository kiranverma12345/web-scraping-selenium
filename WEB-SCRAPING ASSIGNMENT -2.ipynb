{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eed3e5f",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47ce96a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\kiran\\anaconda3\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\kiran\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2228f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f1fd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2773af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri page on automated chrome browser\n",
    "driver.get(' https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4eff35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required in the question -\n",
    "designation =driver.find_element(By.CLASS_NAME,'suggestor-input')\n",
    "designation.send_keys('Data Analyst')                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a39bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching a location\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0804e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on serach button\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25485b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8464107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping 10 job result \n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    #scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "                                \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25cb15fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "# checking length\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878aae01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>S&amp;P Global Inc.</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                      Data Analyst   \n",
       "1                      Data Analyst   \n",
       "2  Data Analyst - IIT/BITS/Startups   \n",
       "3            Data Analyst - FinTech   \n",
       "4            Data Analyst - FinTech   \n",
       "5            Data Analyst - FinTech   \n",
       "6  Data Analyst - IIT/BITS/Startups   \n",
       "7                      Data Analyst   \n",
       "8              Banking Data Analyst   \n",
       "9                      Data Analyst   \n",
       "\n",
       "                                            Location     Company_name  \\\n",
       "0                                Bangalore/Bengaluru              ANZ   \n",
       "1                                Bangalore/Bengaluru              ANZ   \n",
       "2                                Bangalore/Bengaluru     AVE Promagne   \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Ahmedaba...     Primo Hiring   \n",
       "4  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...     Primo Hiring   \n",
       "5  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...     Primo Hiring   \n",
       "6                                Bangalore/Bengaluru     AVE Promagne   \n",
       "7                                Bangalore/Bengaluru  S&P Global Inc.   \n",
       "8  Hyderabad/Secunderabad, Bangalore/Bengaluru, G...          Coforge   \n",
       "9                                Bangalore/Bengaluru          Dpdzero   \n",
       "\n",
       "  Experience  \n",
       "0    6-9 Yrs  \n",
       "1   6-10 Yrs  \n",
       "2    1-5 Yrs  \n",
       "3    1-2 Yrs  \n",
       "4    1-2 Yrs  \n",
       "5    1-2 Yrs  \n",
       "6    1-5 Yrs  \n",
       "7    1-4 Yrs  \n",
       "8   5-10 Yrs  \n",
       "9    1-3 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f269924",
   "metadata": {},
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ff14e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "21ba4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri page on automated chrome browser\n",
    "driver.get(' https://www.naukri.com/ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "63f77c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required in the question -\n",
    "designation =driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "02d6d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching a location\n",
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ac085d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on serach button\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9be3b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping 10 job result \n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    #scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//i[@class=\"fleft placeholder-icons naukicon naukicon-srp-location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "\n",
    "\n",
    "                                \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//i[@class=\"fleft placeholder-icons naukicon naukicon-srp-experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b96de6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50\n"
     ]
    }
   ],
   "source": [
    "# checking length\n",
    "print(len(job_title),len(job_location),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1a874127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Permanent Opportunity For Data scientist with AWS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R&amp;D Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Permanent Opportunity For Data scientist with AWS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>R&amp;D Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Permanent Opportunity For Data scientist with AWS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>R&amp;D Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Permanent Opportunity For Data scientist with AWS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>R&amp;D Specialist</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title Location Experience\n",
       "0                   Manager, Data Solution Specialist                    \n",
       "1                                  Data Scientist_NLP                    \n",
       "2                     Machine Learning (AI) Architect                    \n",
       "3                         Data Science Senior Analyst                    \n",
       "4                                  Research Scientist                    \n",
       "5                                      Data Scientist                    \n",
       "6   Permanent Opportunity For Data scientist with AWS                    \n",
       "7                                      Data Scientist                    \n",
       "8                                      R&D Specialist                    \n",
       "9                                Data Science Analyst                    \n",
       "10                                     Data Scientist                    \n",
       "11                  Manager, Data Solution Specialist                    \n",
       "12                                 Data Scientist_NLP                    \n",
       "13                    Machine Learning (AI) Architect                    \n",
       "14                        Data Science Senior Analyst                    \n",
       "15                                 Research Scientist                    \n",
       "16                                     Data Scientist                    \n",
       "17  Permanent Opportunity For Data scientist with AWS                    \n",
       "18                                     Data Scientist                    \n",
       "19                                     R&D Specialist                    \n",
       "20                                     Data Scientist                    \n",
       "21                  Manager, Data Solution Specialist                    \n",
       "22                                 Data Scientist_NLP                    \n",
       "23                    Machine Learning (AI) Architect                    \n",
       "24                        Data Science Senior Analyst                    \n",
       "25                                 Research Scientist                    \n",
       "26                                     Data Scientist                    \n",
       "27  Permanent Opportunity For Data scientist with AWS                    \n",
       "28                                     Data Scientist                    \n",
       "29                                     R&D Specialist                    \n",
       "30                                     Data Scientist                    \n",
       "31                  Manager, Data Solution Specialist                    \n",
       "32                                 Data Scientist_NLP                    \n",
       "33                    Machine Learning (AI) Architect                    \n",
       "34                        Data Science Senior Analyst                    \n",
       "35                                 Research Scientist                    \n",
       "36                                     Data Scientist                    \n",
       "37  Permanent Opportunity For Data scientist with AWS                    \n",
       "38                                     Data Scientist                    \n",
       "39                                     R&D Specialist                    "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dataframe\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05f777",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "ASSIGNMENT 2\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6041aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7487220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the naukri page on automated chrome browser\n",
    "driver.get(' https://www.naukri.com/ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30ea19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering designation as required in the question -\n",
    "designation =driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "designation.send_keys('Data Scientist')                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eee1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on serach button\n",
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d12ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping 10 job result \n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    #scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "\n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "                                \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5440a3f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22008\\1213014776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# checking length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomp_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_req\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'job_title' is not defined"
     ]
    }
   ],
   "source": [
    "# checking length\n",
    "print(len(job_title),len(loc),len(comp_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b09397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Manager, Data Solution Specialist',\n",
       " 'Data Scientist_NLP',\n",
       " 'Data Science Senior Analyst',\n",
       " 'Research Scientist',\n",
       " 'Machine Learning (AI) Architect',\n",
       " 'Data Science Analyst',\n",
       " 'Data Science Senior Analyst',\n",
       " 'Permanent Opportunity For Data scientist with AWS',\n",
       " 'Data Scientist',\n",
       " 'R&D Specialist',\n",
       " 'Data Science Analyst',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist, Engineering at Google',\n",
       " 'Data Scientist',\n",
       " 'Team Lead/Consultant-Marketing and Customer Analytics',\n",
       " 'Client Engineering - Data Scientist',\n",
       " 'Data Scientist- Bangalore',\n",
       " 'Analytics Specialist - Artificial Intelligence Innovation',\n",
       " 'Analytics Senior Analyst - Artificial Intelligence Innovation']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping required data\n",
    "job_title=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "job=[]\n",
    "for i in job_title:\n",
    "    job.append(i.text)\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61ca5cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Infogain',\n",
       " 'Pfizer',\n",
       " 'Fractal Analytics',\n",
       " 'Accenture',\n",
       " 'Siemens',\n",
       " 'Persistent',\n",
       " 'Accenture',\n",
       " 'Accenture',\n",
       " 'Deloitte',\n",
       " 'Infosys',\n",
       " 'Nokia',\n",
       " 'Accenture',\n",
       " 'IBM',\n",
       " 'Blob Infotech',\n",
       " 'Tech Mahindra',\n",
       " 'Accenture',\n",
       " 'IBM',\n",
       " 'Trigent Software',\n",
       " 'Accenture',\n",
       " 'Accenture']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "company=[]\n",
    "for i in comp_name:\n",
    "    company.append(i.text)\n",
    "    \n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1665f4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '5-11 Yrs',\n",
       " '5-8 Yrs',\n",
       " '2-5 Yrs',\n",
       " '5-12 Yrs',\n",
       " '3-5 Yrs',\n",
       " '5-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '5-6 Yrs',\n",
       " '3-5 Yrs',\n",
       " '7-12 Yrs',\n",
       " '2-7 Yrs',\n",
       " '7-12 Yrs',\n",
       " '7-11 Yrs',\n",
       " '10-12 Yrs',\n",
       " '3-6 Yrs',\n",
       " '7-11 Yrs',\n",
       " '5-8 Yrs']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_req=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "experience=[]\n",
    "for i in exp_req:\n",
    "    experience.append(i.text)\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c403d885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hybrid - Pune, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Mumbai, New Delhi, Bangalore/Bengaluru',\n",
       " 'Mumbai, Pune, Chennai, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, New Delhi, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Mumbai',\n",
       " 'Mumbai',\n",
       " 'Hybrid - Chennai, Coimbatore, Bangalore/Bengaluru, Hyderabad',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Temp. WFH - Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Pune',\n",
       " 'Mumbai',\n",
       " 'Mumbai',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=driver.find_elements(By.XPATH,'//LI[@class=\"fleft br2 placeHolderLi location\"]')\n",
    "location=[]\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "    \n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddbd713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "# checking length\n",
    "print(len(job_title),len(loc),len(comp_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f719499d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPERIENCE_REQUIRED</th>\n",
       "      <th>JOB_LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Hybrid - Pune, Bangalore/Bengaluru, Delhi / NC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager, Data Solution Specialist</td>\n",
       "      <td>Pfizer</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science Senior Analyst</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Permanent Opportunity For Data scientist with AWS</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Hybrid - Chennai, Coimbatore, Bangalore/Bengal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           JOB_TITLE       COMPANY_NAME  \\\n",
       "0                                     Data Scientist           Infogain   \n",
       "1                  Manager, Data Solution Specialist             Pfizer   \n",
       "2                                 Data Scientist_NLP  Fractal Analytics   \n",
       "3                        Data Science Senior Analyst          Accenture   \n",
       "4                                 Research Scientist            Siemens   \n",
       "5                    Machine Learning (AI) Architect         Persistent   \n",
       "6                               Data Science Analyst          Accenture   \n",
       "7                        Data Science Senior Analyst          Accenture   \n",
       "8  Permanent Opportunity For Data scientist with AWS           Deloitte   \n",
       "9                                     Data Scientist            Infosys   \n",
       "\n",
       "  EXPERIENCE_REQUIRED                                       JOB_LOCATION  \n",
       "0             3-6 Yrs  Hybrid - Pune, Bangalore/Bengaluru, Delhi / NC...  \n",
       "1             3-5 Yrs             Mumbai, New Delhi, Bangalore/Bengaluru  \n",
       "2            5-11 Yrs  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...  \n",
       "3             5-8 Yrs                                Bangalore/Bengaluru  \n",
       "4             2-5 Yrs                                Bangalore/Bengaluru  \n",
       "5            5-12 Yrs  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...  \n",
       "6             3-5 Yrs                                             Mumbai  \n",
       "7             5-8 Yrs                                             Mumbai  \n",
       "8             3-8 Yrs  Hybrid - Chennai, Coimbatore, Bangalore/Bengal...  \n",
       "9             3-8 Yrs                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame for the scraped data\n",
    "import pandas as pd\n",
    "df3=pd.DataFrame()\n",
    "df3[\"JOB_TITLE\"]=job[:10]\n",
    "df3[\"COMPANY_NAME\"]=company[:10]\n",
    "df3[\"EXPERIENCE_REQUIRED\"]=experience[:10]\n",
    "df3[\"JOB_LOCATION\"]=location[:10]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0381c921",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "ASSIGNMENT 2\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a1c0cea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8634adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63245e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening flipkart page\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "38b00a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the pop up page\n",
    "pop_up_page =driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "pop_up_page.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5f558393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “sunglasses” and click search button \n",
    "\n",
    "search_product = driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "search_product.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d11e6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the search buttone\n",
    "\n",
    "search_button =driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "07d3b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "94b0700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    brand = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand:Brand.append(i.text)\n",
    "    \n",
    "    product_des = driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in product_des:Product_Description.append(i.text)    \n",
    "    \n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in price:Price.append(i.text)\n",
    "        \n",
    "    time.sleep(3)        \n",
    "        \n",
    "        \n",
    "nxt_button=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']\") #scraping the list of buttons from the page\n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ebd1abe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960 1911 1960\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ebbda61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRODUCT_DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Retro Squ...</td>\n",
       "      <td>₹194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Butterfly Sunglasses (60)</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (55)</td>\n",
       "      <td>₹509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             BRAND                                PRODUCT_DESCRIPTION PRICE\n",
       "0           PIRASO              UV Protection Aviator Sunglasses (54)  ₹212\n",
       "1         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹479\n",
       "2   kingsunglasses  by Lenskart Polarized, UV Protection Retro Squ...  ₹194\n",
       "3    VINCENT CHASE      UV Protection Wayfarer Sunglasses (Free Size)  ₹849\n",
       "4         Fastrack            UV Protection Butterfly Sunglasses (60)  ₹549\n",
       "..             ...                                                ...   ...\n",
       "95   VINCENT CHASE          UV Protection Rectangular Sunglasses (55)  ₹509\n",
       "96          PIRASO     Polarized, UV Protection Round Sunglasses (50)  ₹211\n",
       "97      LIZA ANGEL      UV Protection Wayfarer Sunglasses (Free Size)  ₹199\n",
       "98  kingsunglasses   UV Protection Rectangular Sunglasses (Free Size)  ₹242\n",
       "99   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...  ₹789\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame()\n",
    "df5[\"BRAND\"]=Brand[:100]\n",
    "df5[\"PRODUCT_DESCRIPTION\"]=Product_Description[:100]\n",
    "df5[\"PRICE\"]=Price[:100]\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd76f0",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market \n",
    "place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3350564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f53361fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f2c8f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onpening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23224059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the pop up page\n",
    "pop_up_page =driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "pop_up_page.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdc13ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “iphone 11” and click search button \n",
    "\n",
    "search_product = driver.find_element(By.CLASS_NAME,'_3704LK')\n",
    "search_product.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11a4fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the search button\n",
    "\n",
    "search_button =driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0138a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets select the first phone\n",
    "\n",
    "click_first_phone =driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[1]\")\n",
    "click_first_phone.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a41cf6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rating, Review_summary, Full_review]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []\n",
    "\n",
    "rating = driver.find_elements(By.XPATH,'//div[@class=\"_2QKOHZ\"]')\n",
    "review = driver.find_elements(By.XPATH,'//div[@class=\"_2QKOHZ\"]')\n",
    "full_review = driver.find_elements(By.XPATH,'//div[@class=\"_3UAT2v _16PBlm\"]')\n",
    "\n",
    "#for page in range(0,3):\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "for o in review:\n",
    "    Review_summary.append(o.text)\n",
    "for p in full_review:\n",
    "    Full_review.append(p.text)    \n",
    "    \n",
    "df = pd.DataFrame({'Rating':rating,'Review_summary':review,'Full_review':full_review})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e11506",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "380c3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "71e0a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ee8b77a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "db0404e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_close = driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "pop_close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "412d1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_item = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_item.send_keys(\"sneakers\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cc97c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_search_button = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "click_search_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ad12a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price = []\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    brand = driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    product_des = driver.find_elements(By.XPATH,\"//div[@class='_2B099V']/a[1]\")\n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    " \n",
    "\n",
    "\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "    for i in product_des:\n",
    "        Product_Description.append(i.text)\n",
    "    for i in price :\n",
    "        Price.append(i.text)\n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "nxt_button = driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']\")\n",
    "nxt_button.click() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "75fcbd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "86defca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>₹269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium Sports Shoes For Men Pack Of 2 Sneaker...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Sparx</td>\n",
       "      <td>SD-323 Sneakers For Men</td>\n",
       "      <td>₹845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shuzer68</td>\n",
       "      <td>Stylish Trendy Cool Light Weight Premium Sneak...</td>\n",
       "      <td>₹623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>₹269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                Product_Description Price\n",
       "0   RapidBox                                   Sneakers For Men  ₹579\n",
       "1   RapidBox                                   Sneakers For Men  ₹699\n",
       "2       aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...  ₹269\n",
       "3      BIRDE  Premium Sports Shoes For Men Pack Of 2 Sneaker...  ₹449\n",
       "4      BIRDE      Combo Pack Of 2 Casual Shoes Sneakers For Men  ₹449\n",
       "..       ...                                                ...   ...\n",
       "95    Labbin                                   Sneakers For Men  ₹379\n",
       "96     Sparx                            SD-323 Sneakers For Men  ₹845\n",
       "97  Shuzer68  Stylish Trendy Cool Light Weight Premium Sneak...  ₹623\n",
       "98     BIRDE      Combo Pack of 2 Casual Shoes Sneakers For Men  ₹449\n",
       "99    BRUTON               Modern Trendy Shoes Sneakers For Men  ₹269\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand':Brand,'Product_Description':Product_Description,'Price':Price})\n",
    "\n",
    "df[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc4141",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8f68439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c815e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1641829",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab0a7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_item = driver.find_element(By.XPATH,\"//input[@class='nav-input nav-progressive-attribute']\")\n",
    "search_item.send_keys(\"laptop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3cca46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_search_button = driver.find_element(By.XPATH,\"//input[@id='nav-search-submit-button']\")\n",
    "click_search_button.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "475eb92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lenovo IdeaPad Gaming 3 Intel Core i5 12th Gen 15.6\" (39.62cm) FHD IPS Gaming Laptop (16GB/512GB SDD/4GB NVIDIA RTX 3050/120Hz/Win11/Office 2021/Backlit/3months Game Pass/Onyx Grey/2.32Kg), 82S900R6IN', 'Acer Aspire 5 Gaming Laptop Intel Core i5 12th gen (12-Cores) Processor (16 GB/512 GB SSD/Win11 Home/4GB Graphics/RTX 2050) A515-57G (15.6\" FHD Display, 1.8 Kg)', 'Lenovo E41-55 AMD 14-inch HD 220 Nits Antiglare Thin and Light Laptop (Athlon Silver 3050U/8GB RAM/256 SSD/DOS/Integrated AMD Graphics/Grey/1 Year Onsite/1.59 kg)', 'Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11th Gen 15.6\" (39.62cm) FHD Laptop (8GB/256GB SSD/Win 11/Office 2021/2 Year Warranty/3 Month Game Pass/Platinum Grey/1.7Kg), 81X800LCIN', 'HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/512GB SSD 15.6-inch(39.6 cm) Micro-Edge Anti-Glare FHD Laptop/Alexa Built-in/Win 11/Intel UHD Graphics/Dual Speakers/MS Office 2021/1.69 Kg, 15s-fq2673TU', 'Apple 2022 MacBook Air Laptop with M2 chip: 34.46 cm (13.6-inch) Liquid Retina Display, 8GB RAM, 256GB SSD Storage, Backlit Keyboard, 1080p FaceTime HD Camera. Works with iPhone/iPad; Silver', 'HP 15s, 11th Gen Intel Core i3 8GB RAM/1TB HDD+256 GB SSD 15.6-inches/39.6 cm FHD Laptop/Windows 11/Intel UHD Graphics/Dual Speakers/Alexa/MSO/Fast Charge/1.75 Kg, 15s-du3614TU', 'Lenovo ThinkBook 15 Intel Core i5 1235U 15.6\" (39.62cm) FHD 220 Nits Antiglare Thin and Light Laptop (16GB/1TB SSD/Windows 11 Home/MS Office/Mineral Grey/1.7 Kg/Backlit), 21DJA0D9IH', 'Dell Vostro 3420 Laptop,12th Gen Intel Core i3-1215U, 8GB & 512GB SSD, 14.0\" (35.56Cms) FHD WVA AG 250 nits, Win11+MSO\\'21, 15 Month McAfee, Black, 1.48 KGs', 'HP 15s, 12th Gen Intel Core i5 8GB RAM/512GB SSD 15.6-inch(39.6 cm) Micro-Edge Anti-Glare FHD Laptop/Intel Iris Xe Graphics/Alexa/Dual Speakers/Win 11/MSO 2021/1.41 Kg, 15s- fq5111TU']\n",
      "['', '', '', '', '', '', '', '', '', '']\n",
      "['84,990', '63,990', '20,999', '39,000', '40,990', '1,06,990', '40,990', '66,990', '42,990', '54,990']\n"
     ]
    }
   ],
   "source": [
    "#scraping details of first 10 laptops for core i7 there title, ratings and price\n",
    "title=[]\n",
    "ratings=[]\n",
    "price=[]\n",
    "name=driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "rat=driver.find_elements(By.XPATH,\"//span[@class='a-icon-alt']\")\n",
    "pr=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in range(10):\n",
    "    title.append(name[i].text)\n",
    "    ratings.append(rat[i].text)\n",
    "    price.append(pr[i].text)\n",
    "print(title)\n",
    "print(ratings)\n",
    "print(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f1db506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(ratings),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddb8c75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 Intel Core i5 12th Gen...</td>\n",
       "      <td></td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Aspire 5 Gaming Laptop Intel Core i5 12th...</td>\n",
       "      <td></td>\n",
       "      <td>63,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo E41-55 AMD 14-inch HD 220 Nits Antiglar...</td>\n",
       "      <td></td>\n",
       "      <td>20,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...</td>\n",
       "      <td></td>\n",
       "      <td>39,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...</td>\n",
       "      <td></td>\n",
       "      <td>40,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Apple 2022 MacBook Air Laptop with M2 chip: 34...</td>\n",
       "      <td></td>\n",
       "      <td>1,06,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP 15s, 11th Gen Intel Core i3 8GB RAM/1TB HDD...</td>\n",
       "      <td></td>\n",
       "      <td>40,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel Core i5 1235U 15.6\" ...</td>\n",
       "      <td></td>\n",
       "      <td>66,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Vostro 3420 Laptop,12th Gen Intel Core i3...</td>\n",
       "      <td></td>\n",
       "      <td>42,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 15s, 12th Gen Intel Core i5 8GB RAM/512GB S...</td>\n",
       "      <td></td>\n",
       "      <td>54,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  Lenovo IdeaPad Gaming 3 Intel Core i5 12th Gen...            84,990\n",
       "1  Acer Aspire 5 Gaming Laptop Intel Core i5 12th...            63,990\n",
       "2  Lenovo E41-55 AMD 14-inch HD 220 Nits Antiglar...            20,999\n",
       "3  Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...            39,000\n",
       "4  HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...            40,990\n",
       "5  Apple 2022 MacBook Air Laptop with M2 chip: 34...          1,06,990\n",
       "6  HP 15s, 11th Gen Intel Core i3 8GB RAM/1TB HDD...            40,990\n",
       "7  Lenovo ThinkBook 15 Intel Core i5 1235U 15.6\" ...            66,990\n",
       "8  Dell Vostro 3420 Laptop,12th Gen Intel Core i3...            42,990\n",
       "9  HP 15s, 12th Gen Intel Core i5 8GB RAM/512GB S...            54,990"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(list(zip(title[0:10],ratings[0:10],price[0:10])),columns=[\"Title\",\"Ratings\",\"Price\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede02727",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e5b3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bb6ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13e77cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the required web page\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ef640f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_item=driver.find_element(By.XPATH,'//a[@href=\"/top_quotes.html\"]')\n",
    "search_item.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85963cd0",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "438a184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6cb88ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de6119b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the required web page\n",
    "driver.get('https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35ad39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_gk=driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "search_gk.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de1fb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_PM=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "search_PM.click() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db980be",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94267d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d644972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the webdriver\n",
    "driver=webdriver.Chrome(r'‪chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "94644925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the required web page\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d2c9bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu=driver.find_element(By.XPATH,'/html/body/div[3]/div[2]/div/div/div[1]/div')\n",
    "menu.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2fb180c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_item = driver.find_element(By.XPATH,'/html/body/div[3]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "search_item.send_keys('50 most expensive cars in the word')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
